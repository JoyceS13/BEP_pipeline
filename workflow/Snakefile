# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

import numpy as np
import os

configfile: "/tudelft.net/staff-umbrella/YeastVariantCalling/wsung/BEP_pipeline/config/test_config.yaml"
	
## some variables that might be nice to define at the top of the document -> put in config file
#general variables, maybe move to config file
reference = config["reference"]
name = config["name"]
mutations = config["mutations"]
repeats = config["repeats"]
f_cov = config["f_cov"]
rename_file = config["rename_file"]
ploidy = config["ploidy"]
varscan_filter = config["varscan_filter"]

#dependent global variables
repeat_ar = range(0,repeats)
props = "_".join(str(cov) for cov in f_cov)
pop_size = len(f_cov)
pop_size_ar = range(0,pop_size)
outdir = f"output/{name}_{mutations}mut_{props}fcov"
prefix = f"{name}_{mutations}mut_{pop_size}_pop"

#uncomment one line to target specific rule
rule all_test:
	input:
		#expand("output/test/sample{ii}/seq_{jj}.fasta", ii = repeat_ar,jj = pop_size_ar) #mutate
		#expand("output/test/sample{ii}/seq_{jj}_{read_end}.fq", ii = repeat_ar, jj = pop_size_ar, read_end = [1,2]) #make_samples
		expand("output/test/sample{ii}/reads{read_end}.fq", ii = repeat_ar,read_end = [1,2]) #group_reads
		#expand("output/test/sample{ii}/aln.srt.bam", ii = repeat_ar),expand("output/test/sample{ii}/aln.srt.bam.bai", ii =repeat_ar) #bwa_map
		#expand("output/test/sample{ii}/vcf/octopus.vcf", ii=repeat_ar) #octopus_call
		#expand("output/test/sample{ii}/vcf/gatk.vcf", ii=repeat_ar) #gatk_call
		#expand("output/test/sample{ii}/vcf/varscan.vcf", ii=repeat_ar) #varscan_call
		#expand("output/test/sample{ii}/vcf/freebayes.vcf", ii=repeat_ar) #freebayes_call
		#expand("output/test/sample{ii}/vcf/true_vcf_seq{jj}.vcf", ii = repeat_ar, jj = pop_size_ar) #msa2vcf
		#expand("output/test/sample{ii}/vcf/comparison/{caller}_seq{jj}.diff.sites_in_files", ii = repeat_ar, caller = ['gatk','varscan','freebayes','gatk_upper','gatk_lower','gatk_unfiltered','varscan_unfiltered','freebayes_unfiltered'], jj = pop_size_ar)
		#expand("output/test/sample{ii}/analysis/analysis_{caller}.csv", ii = repeat_ar, caller = ['gatk','varscan','freebayes','gatk_upper','gatk_lower','gatk_unfiltered','varscan_unfiltered','freebayes_unfiltered'])
		#expand("output/test/results_{caller}.csv", caller = ['gatk','varscan','freebayes','gatk_upper','gatk_lower','gatk_unfiltered','varscan_unfiltered','freebayes_unfiltered'])
		
#mutate reference sequence
rule mutate:
	input:
		reference
	output:
	  	expand("{{outdir}}/sample{{ii}}/seq_{jj}.fasta", jj = pop_size_ar)
	params:
		out_prefix = "seq",
		mutations = mutations,
		pop_size = pop_size,
		out_dir = "{outdir}/sample{ii}"
	conda:
		"envs/mutate_env.yaml"
	script:
	  	"scripts/mutator.py"
	

#simulate reads from mutated sequences
##needs to be altered so it can be used for different proportions and different population sizes
rule make_samples:
	input:
		"{outdir}/sample{ii}/seq_{jj}.fasta"
	output:
		temp(expand("{{outdir}}/sample{{ii}}/seq_{{jj}}_{read_end}.fq", read_end = [1,2]))
	params:
		out_prefix ="{outdir}/sample{ii}/seq_{jj}_" ,
		fcov = lambda wildcards: f_cov[int(wildcards.jj)],
		out_dir = "{outdir}/sample{ii}"
	run:
		shell("cd {params.out_dir}")
		shell("art_illumina -na -i {input} -p -l 150 -ss HS25 -f {params.fcov} -m 200 -s 10 -o {params.out_prefix}")

#group reads such that a certain population size is simulated 
rule group_reads:
  	input:
	  	expand("{{outdir}}/sample{{ii}}/seq_{jj}_{{read_end}}.fq", jj = pop_size_ar),
	output:
		"{outdir}/sample{ii}/reads{read_end}.fq"
	shell:
		"cat {input} > {output}"
		
#maps reads, adds read group information (for GATK calling), and converts it into sorted bam, additionally indexes the file
rule bwa_map:
  	input:
	  	reference,
	  	expand("{{outdir}}/sample{{ii}}/reads{read_end}.fq", read_end = [1,2])
  	output:
	  	"{outdir}/sample{ii}/aln.srt.bam",
		"{outdir}/sample{ii}/aln.srt.bam.bai"
	conda:
		"envs/bwa_map_env.yaml"
	run:
	  	shell("bwa mem {input} | samtools addreplacerg -r ID:dummy -r LB:dummy -r SM:dummy -r PL:ILLUMINA - | samtools view -1 - | samtools sort - > {output[0]}")
		shell("samtools index {output[0]}")

#after creation some vcf headers and/or chromosome names are adjusted
rule bcftools_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		"{outdir}/sample{ii}/vcf/bcftools.vcf"
	params:
		ploidy = pop_size
	conda:
		"envs/bcftools.yaml"
	shell:
		"samtools mpileup -uf {input} | bcftools call --ploidy params.ploidy -m -o {output}"

rule bcftools_limit:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		"{outdir}/sample{ii}/vcf/bcftools_limit.vcf"
	params:
		ploidy = 5
	conda:
		"envs/bcftools.yaml"
	shell:
		"samtools mpileup -uf {input} | bcftools call --ploidy params.ploidy -m -o {output}"
		
rule octopus_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/octopus.vcf"
	conda:
		"envs/octopus.yaml"
	shell:
		"octopus -R {input[0]} -I {input[1]} -C polyclone | bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"
		
rule gatk_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk.vcf"
	params:
		ploidy = ploidy
	conda:
		"envs/gatk4.yaml"
	run:
		shell("gatk CreateSequenceDictionary -R {input[0]}")
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 1 | bcftools annotate --rename-chrs {input.rename_file} - > unfiltered.vcf")
		shell("gatk VariantFiltration -V unfiltered.vcf -filter "QD < 2.0" --filter-name "QD2" -filter "QUAL < 30.0" --filter-name "QUAL30" -filter "SOR > 3.0" --filter-name "SOR3" -filter "FS > 60.0" --filter-name "FS60"  -filter "MQ < 40.0" --filter-name "MQ40"  -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5"  -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" -O {output}")

rule gatk_call_upper:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_upper.vcf"
	params:
		ploidy = 5
	conda:
		"envs/gatk4.yaml"
	run:
		shell("gatk CreateSequenceDictionary -R {input[0]}")
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 1 | bcftools annotate --rename-chrs {input.rename_file} - > unfiltered.vcf")
		shell("gatk VariantFiltration -V unfiltered.vcf -filter "QD < 2.0" --filter-name "QD2" -filter "QUAL < 30.0" --filter-name "QUAL30" -filter "SOR > 3.0" --filter-name "SOR3" -filter "FS > 60.0" --filter-name "FS60"  -filter "MQ < 40.0" --filter-name "MQ40"  -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5"  -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" -O {output}")

rule gatk_call_lower:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_lower.vcf"
	params:
		ploidy = 2
	conda:
		"envs/gatk4.yaml"
	run:
		shell("gatk CreateSequenceDictionary -R {input[0]}")
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 1 | bcftools annotate --rename-chrs {input.rename_file} - > unfiltered.vcf")
		shell("gatk VariantFiltration -V unfiltered.vcf -filter "QD < 2.0" --filter-name "QD2" -filter "QUAL < 30.0" --filter-name "QUAL30" -filter "SOR > 3.0" --filter-name "SOR3" -filter "FS > 60.0" --filter-name "FS60"  -filter "MQ < 40.0" --filter-name "MQ40"  -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5"  -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" -O {output}")
		
		
rule gatk_unfiltered_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_unfiltered.vcf"
	params:
		ploidy = ploidy
	conda:
		"envs/gatk4.yaml"
	run:
		shell("gatk CreateSequenceDictionary -R {input[0]}")
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 1 | bcftools annotate --rename-chrs {input.rename_file} - > {output}")		
		
rule varscan_call:
	input: 
		reference = reference,
		unfiltered_call = "{outdir}/sample{ii}/vcf/varscan_unfiltered.vcf",
		bam = "{outdir}/sample{ii}/aln.srt.bam"
	output:
		"{outdir}/sample{ii}/vcf/varscan.vcf"
	conda:
		"envs/varscan.yaml"
	shell:
		"bam-readcount –q 1 –b 20 –f {input.reference} –l {input.unfiltered_call} {input.bam} | perl fpfilter.pl {input.unfiltered_call} - –output-basename {output}"

rule varscan_call_unfiltered:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/varscan_unfiltered.vcf"
	conda:
		"envs/varscan.yaml"
	shell:
		"samtools mpileup -f {input} | varscan mpileup2snp - --output-vcf 1 --min-coverage 10 --min-var-freq 0.10 --p-value 0.10 | bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"

rule freebayes_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/freebayes.vcf"
	conda:
		"envs/freebayes.yaml"
	shell:
		"freebayes -f {input[0]} -p 1 --pooled-continuous -0 {input[1]} | bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"

rule freebayes_call_unfiltered:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/freebayes_unfiltered.vcf"
	conda:
		"envs/freebayes.yaml"
	shell:
		"freebayes -f {input[0]} -p 1 --pooled-continuous {input[1]} | bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"
		

rule seq2msa:
	input:
		reference,
		"{outdir}/sample{ii}/seq{jj}.fasta"
	output:
		temp("{outdir}/sample{ii}/msa/msa_seq{jj}.msa")
	shell:
		"cat {input} > {output}"

rule msa2vcf:
	input: 
		"{outdir}/sample{ii}/msa/msa_seq{jj}.msa"
	output:
		"{outdir}/sample{ii}/vcf/true_vcf_seq{jj}.vcf"
	conda:
		"envs/snp-sites.yaml"
	shell:
		"snp-sites -v -o {output} {input}"	       

rule comparison_vcfs:
	input:
		"{outdir}/sample{ii}/vcf/{caller}.vcf",
		"{outdir}/sample{ii}/vcf/true_vcf_seq{jj}.vcf"
	output:
		temp("{outdir}/sample{ii}/vcf/comparison/{caller}_seq{jj}.diff.sites_in_files")
	params:
		out_prefix = "{caller}_seq{jj}"
	conda:
		"envs/vcftools.yaml"
	shell:
		"vcftools --vcf {input[0]} --diff {input[1]} --diff-site --out params.out_prefix"
		
rule validate:
	input:
		comparison_vcfs = expand("{{outdir}}/sample{{ii}}/vcf/comparison/{{caller}}_seq{jj}.diff.sites_in_files", jj = pop_size_ar),
		reference = reference
	output:
		"{outdir}/sample{ii}/analysis/analysis_{caller}.csv"	
	params:
		sample_index = "{ii}",
		caller = "{caller}",
		out_dir = "{outdir}/sample{ii}/analysis"
	conda:
		"envs/validate_env.yaml"
	script:
		"scripts/validate.py"
		
rule data_collection:
	input:
		expand("{{outdir}}/sample{ii}/analysis/analysis_{{caller}}.csv", ii = repeat_ar)
	output:
		"{outdir}/results_{caller}.csv"
	conda:
		"envs/validate_env.py"
	params:
		caller = "{caller}",
		out_dir = "{outdir}"
	script:
		"scripts/data_collection.py"

