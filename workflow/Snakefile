# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

import numpy as np

configfile: "/tudelft.net/staff-umbrella/YeastVariantCalling/wsung/BEP_pipeline/config/test_config.yaml"
	
## some variables that might be nice to define at the top of the document -> put in config file
#general variables, maybe move to config file
reference = config["reference"]
name = config["name"]
mutations = config["mutations"]
repeats = config["repeats"]
f_cov = config["f_cov"]
rename_file = config["rename_file"]

#dependent global variables
repeat_ar = range(0,repeats)
props = "_".join(str(cov) for cov in f_cov)
pop_size = len(f_cov)
pop_size_ar = range(0,pop_size)
outdir = f"output/{name}_{mutations}mut_{props}fcov"
prefix = f"{name}_{mutations}mut_{pop_size}_pop"

#rule all:

#mutate reference sequence
rule mutate:
	input:
		reference
	output:
	  	expand("{{outdir}}/sample{{ii}}/seq_{jj}.fasta", jj = pop_size_ar)
	params:
		out_prefix = "seq",
		mutations = mutations,
		pop_size = pop_size
	conda:
		"envs/mutate_env.yaml"
	shell:
	  	"scripts/mutator.py"
	

#simulate reads from mutated sequences
##needs to be altered so it can be used for different proportions and different population sizes
rule make_samples:
	input:
		expand("{{outdir}}/sample{{ii}}/seq_{jj}.fasta", jj = pop_size_ar)
	output:
		temp(expand("{{outdir}}/sample{{ii}}/seq_{jj}_{read_end}.fq", jj = pop_size_ar, read_end = [1,2]))
	params:
		out_prefix =expand("seq_{jj}_",jj=pop_size_ar) ,
		f_cov = f_cov
	run:
		for ii in pop_size_ar:
			shell("art_illumina -sam -i {input[ii]} -p -l 150 -ss HS25 -f {params.f_cov[ii]} -m 200 -s 10 -o {params.out_prefix}")

#group reads such that a certain population size is simulated 
rule group_reads:
  	input:
	  	reads1 = expand("{{outdir}}/sample{{ii}}/seq_{jj}_1.fq", jj = pop_size_ar),
		reads2 = expand("{{outdir}}/sample{{ii}}/seq_{jj}_2.fq", jj = pop_size_ar)
	output:
		expand("{{outdir}}/sample{{ii}}/reads{read_end}.fq", read_end = [1,2])
	shell:
		"cat input.reads1 > reads1.fq"
		"cat input.reads2 > reads2.fq"
		
#maps reads, adds read group information (for GATK calling), and converts it into sorted bam, additionally indexes the file
rule bwa_map:
  	input:
	  	reference,
	  	expand("{{outdir}}/sample{{ii}}/reads{read_end}.fq", read_end = [1,2])
  	output:
	  	"{outdir}/sample{ii}/aln.srt.bam"
		"{outdir}/sample{ii}/aln.srt.bam.bai"
	conda:
		"envs/bwa_map_env.yaml"
	shell:
	  	"bwa mem {input} | samtools addreplacerg -r ID:dummy -r LB:dummy -r SM:dummy -r PL:ILLUMINA - | samtools view -1 - | samtools sort - > {output[0]}"
		"samtools index {output[0]}"

#after creation some vcf headers and/or chromosome names are adjusted
rule bcftools_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		"{outdir}/sample{ii}/vcf/bcftools.vcf"
	params:
		ploidy = pop_size
	conda:
		"envs/bcftools.yaml"
	shell:
		"bcftools mpileup -f {input} | bcftools call --ploidy params.ploidy -m -o {output}"

rule bcftools_limit:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		"{outdir}/sample{ii}/vcf/bcftools_limit.vcf"
	params:
		ploidy = 5
	conda:
		"envs/bcftools.yaml"
	shell:
		"bcftools mpileup -f {input} | bcftools call --ploidy params.ploidy -m -o {output}"
		
rule gatk_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk.vcf"
	conda:
		"envs/gatk4.yaml"
	shell:
		"gatk CreateSequenceDictionary -R {input[0]}"
		"gatk HaplotypeCaller -R {input[0]} -I {input[1]} | bcftools annotate --rename-chrs {input.rename_file} - > {output}"

rule varscan_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		temp("{outdir}/sample{ii}/vcf/varscan_temp.vcf")
	conda:
		"envs/varscan.yaml"
	shell:
		"samtools mpileup -f {input} | varscan mpileup2snp - --output-vcf 1 | "bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"

rule freebayes_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam"
	output:
		temp("{outdir}/sample{ii}/vcf/freebayes.vcf")
	conda:
		"envs/freebayes.yaml"
	shell:
		"freebayes -f {input[0]} -p 1 {input[1]} | "bgzip -c - | tabix -p vcf - | bcftools annotate --rename-chrs {input.rename_file} - > {output}"
	
rule seq2msa:
	input:
		reference,
		"{outdir}/sample{ii}/seq{jj}.fasta"
	output:
		temp("{outdir}/sample{ii}/msa/msa_seq{jj}.msa")
	shell:
		"cat {input} > {output}"

rule msa2vcf:
	input: 
		"{outdir}/sample{ii}/msa/msa_seq{jj}.msa"
	output:
		"{outdir}/sample{ii}/vcf/true_vcf_seq{jj}.vcf"
	conda:
		"envs/snp-sites.yaml"
	shell:
		"snp-sites -v -o {output} {input}"	       

rule comparison_vcfs:
	input:
		"{outdir}/sample{ii}/vcf/{caller}.vcf"
		"{outdir}/sample{ii}/vcf/true_vcf_seq{jj}.vcf"
	output:
		temp("{outdir}/sample{ii}/vcf/comparison/{caller}_seq{jj}.diff.sites_in_files")
	params:
		out_prefix = {caller}_seq{jj}
	conda:
		"envs/vcftools.yaml"
	shell:
		"vcftools --vcf {input[0]} --diff {input[1]} --diff-site --out params.out_prefix"
		
rule validate:
	input:
		expand("{{outdir}}/sample{{ii}}/vcf/comparison/{{caller}}_seq{jj}.diff.sites_in_files", jj = pop_size_ar)
	output:
		"{outdir}/sample{ii}/analysis.csv"
	shell:	
		"python /tudelft.net/staff-umbrella/YeastVariantCalling/wsung/validate.py varscan_snps0.diff.sites_in_files varscan_snps1.diff.sites_in_files -r /tudelft.net/staff-umbrella/YeastVariantCalling/wsung/IMBvariant/reference/chromosomes/CEN.PK113-7D_chr01_pilon.fa
		
		


