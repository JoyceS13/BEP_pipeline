# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

import numpy as np
import os

configfile: "/tudelft.net/staff-umbrella/YeastVariantCalling/wsung/BEP_pipeline/config/config50cov_10rep.yaml"
	
## some variables that might be nice to define at the top of the document -> put in config file
#general variables, maybe move to config file
reference = config["reference"]
name = config["name"]
mutations = config["mutations"]
repeats = config["repeats"]
f_cov = config["f_cov"]
proportions = np.array(config["props"])
rename_file = config["rename_file"]
varscan_filter = config["varscan_filter"]
caller_ar = config["callers"]

def create_names(proportions):
        props = []
        for proportion in proportions:
                props.append("_".join(str(cov) for cov in proportion))
        return props

#dependent global variables
repeat_ar = range(0,repeats)
props = create_names(proportions)

#uncomment one line to target specific rule
rule all_test:
	input:
		#expand("output/test/sample{ii}/seq_{jj}.fasta", ii = repeat_ar,jj = pop_size_ar) #mutate
		#expand("output/test/sample{ii}/seq_{jj}_{read_end}.fq", ii = repeat_ar, jj = pop_size_ar, read_end = [1,2]) #make_samples
		#expand("output/test/sample{ii}/reads{read_end}.fq", ii = repeat_ar,read_end = [1,2]) #group_reads
		#expand("output/test/sample{ii}/aln.srt.bam", ii = repeat_ar),expand("output/test/sample{ii}/aln.srt.bam.bai", ii =repeat_ar) #bwa_map
		#expand("output/test/sample{ii}/vcf/octopus.vcf", ii=repeat_ar) #octopus_call
		#expand("output/test/sample{ii}/vcf/gatk.vcf", ii=repeat_ar) #gatk_call
		#expand("output/test/sample{ii}/vcf/varscan.vcf", ii=repeat_ar) #varscan_call
		#expand("output/test/sample{ii}/vcf/freebayes.vcf", ii=repeat_ar) #freebayes_call
		#expand("output/test/sample{ii}/vcf/true_vcf_seq{jj}.vcf", ii = repeat_ar, jj = pop_size_ar) #msa2vcf
		#expand("output/test/sample{ii}/vcf/comparison/{caller}_seq{jj}.diff.sites_in_files", ii = repeat_ar, caller = caller_ar, jj = pop_size_ar)
		#expand("output/test/sample{ii}/analysis/analysis_{caller}.csv", ii = repeat_ar, caller = caller_ar)
		expand("output/{fcov}fcov/{props}props/results_{caller}.csv", \
		       fcov = f_cov, props = props, caller = caller_ar)
		
#get correct parameters to run		
def get_pop_range(props, outdir, proportions):
	for ii, prop in enumerate(props):
		if prop in outdir:
			jj = range(0,len(proportions[ii]))
	return jj

def get_pop_range(props, outdir, proportions, f_cov, jj):
	for ii, prop in enumerate(props):
		if prop in outdir:
			proportion = proportions[ii][jj]
	for ii, cov in enumerate(f_cov):
		if str(cov)+"fcov" in outdir:
			coverage = cov
	fcov = coverage*proportion
	return fcov
		

#mutate reference sequence
rule mutate:
	input:
		reference
	output:
	  	expand("{{outdir}}/sample{{ii}}/seq_{jj}.fasta", \
		       jj = lambda wildcards:get_pop_range(props, wildcards.outdir, proportions))
	params:
		out_prefix = "seq",
		mutations = mutations,
		pop_size = pop_size,
		out_dir = "{outdir}/sample{ii}"
	conda:
		"envs/mutate_env.yaml"
	script:
	  	"scripts/mutator.py"

#simulate reads from mutated sequences
##needs to be altered so it can be used for different proportions and different population sizes
rule make_samples:
	input:
		"{outdir}/sample{ii}/seq_{jj}.fasta"
	output:
		temp(expand("{{outdir}}/sample{{ii}}/seq_{{jj}}_{read_end}.fq", read_end = [1,2]))
	params:
		out_prefix ="{outdir}/sample{ii}/seq_{jj}_" ,
		fcov = lambda wildcards: get_fcov(props, wildcards.outdir, proportions, f_cov, wildcards.jj),
		out_dir = "{outdir}/sample{ii}"
	run:
		shell("art_illumina -na -i {input} -p -l 150 -ss HS25 -f {params.fcov} -m 200 -s 10 -o {params.out_prefix}")

#group reads such that a certain population size is simulated 
rule group_reads:
  	input:
	  	expand("{{outdir}}/sample{{ii}}/seq_{jj}_{{read_end}}.fq", \
		       jj = lambda wildcards:get_pop_range(props, wildcards.outdir, proportions))
	output:
		"{outdir}/sample{ii}/reads{read_end}.fq"
	shell:
		"cat {input} > {output}"
		
#maps reads, adds read group information (for GATK calling), and converts it into sorted bam, additionally indexes the file
rule bwa_map:
  	input:
	  	reference,
	  	expand("{{outdir}}/sample{{ii}}/reads{read_end}.fq", read_end = [1,2])
  	output:
	  	"{outdir}/sample{ii}/aln.srt.bam",
		"{outdir}/sample{ii}/aln.srt.bam.bai",
		sam = temp("{outdir}/sample{ii}/aln.sam")
	run:
	  	shell("bwa mem {input} >{output.sam}")
		shell("samtools addreplacerg -r ID:dummy -r LB:dummy -r SM:dummy -r PL:ILLUMINA {output.sam} \
			| samtools view -1 - | samtools sort - > {output[0]}")
		shell("samtools index {output[0]}")
		#shell("gatk CreateSequenceDictionary -R {input[0]}")

#after creation some vcf headers and/or chromosome names are adjusted
	
rule gatk_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp1_gatk.vcf"),
		temp_unfiltered = temp("{outdir}/sample{ii}/vcf/temp1_unfiltered_gatk.vcf")
	params:
		ploidy = len(get_pop_range(props, outdir, proportions)),
		QD = "QD<2.0",
		QUAL = "QUAL<30.0",
		SOR = "SOR>3.0",
		FS = "FS>60.0",
		MQ = "MQ<40.0",
		MQRankSum = "MQRankSum<-12.5",
		RPRS = "ReadPosRankSum<-8.0",
	run:
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy {params.ploidy} -O {output.temp_file}")
		shell("bcftools annotate --rename-chrs {input.rename_file} {output.temp_file} > {output.temp_unfiltered}")
		shell("gatk VariantFiltration -V {params.temp_unfiltered} \
			-filter {params.QD:q} --filter-name QD2 \
			-filter {params.QUAL:q} --filter-name QUAL30 \
			-filter {params.SOR:q} --filter-name SOR3 \
			-filter {params.FS:q} --filter-name FS60 \
			-filter {params.MQ:q} --filter-name MQ40 \
			-filter {params.MQRankSum:q} --filter-name MQRankSum-12.5  \
			-filter {params.RPRS:q} --filter-name ReadPosRankSum-8 
		      	-O {output[0]}")
		
rule gatk_call_upper:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_upper.vcf"
	temp_file = temp("{outdir}/sample{ii}/vcf/temp2_gatk.vcf"),
		temp_unfiltered = temp("{outdir}/sample{ii}/vcf/temp2_unfiltered_gatk.vcf")
	params:
		QD = "QD<2.0",
		QUAL = "QUAL<30.0",
		SOR = "SOR>3.0",
		FS = "FS>60.0",
		MQ = "MQ<40.0",
		MQRankSum = "MQRankSum<-12.5",
		RPRS = "ReadPosRankSum<-8.0",
	run:
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 5 -O {output.temp_file}")
		shell("bcftools annotate --rename-chrs {input.rename_file} {output.temp_file} > {output.temp_unfiltered}")
		shell("gatk VariantFiltration -V {params.temp_unfiltered} \
			-filter {params.QD:q} --filter-name QD2 \
			-filter {params.QUAL:q} --filter-name QUAL30 \
			-filter {params.SOR:q} --filter-name SOR3 \
			-filter {params.FS:q} --filter-name FS60 \
			-filter {params.MQ:q} --filter-name MQ40 \
			-filter {params.MQRankSum:q} --filter-name MQRankSum-12.5  \
			-filter {params.RPRS:q} --filter-name ReadPosRankSum-8 
		      	-O {output[0]}")
		
rule gatk_call_lower:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_lower.vcf"
		temp_file = temp("{outdir}/sample{ii}/vcf/temp3_gatk.vcf"),
		temp_unfiltered = temp("{outdir}/sample{ii}/vcf/temp3_unfiltered_gatk.vcf")
	params:
		QD = "QD<2.0",
		QUAL = "QUAL<30.0",
		SOR = "SOR>3.0",
		FS = "FS>60.0",
		MQ = "MQ<40.0",
		MQRankSum = "MQRankSum<-12.5",
		RPRS = "ReadPosRankSum<-8.0",
	run:
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy 1 -O {output.temp_file}")
		shell("bcftools annotate --rename-chrs {input.rename_file} {output.temp_file} > {output.temp_unfiltered}")
		shell("gatk VariantFiltration -V {params.temp_unfiltered} \
			-filter {params.QD:q} --filter-name QD2 \
			-filter {params.QUAL:q} --filter-name QUAL30 \
			-filter {params.SOR:q} --filter-name SOR3 \
			-filter {params.FS:q} --filter-name FS60 \
			-filter {params.MQ:q} --filter-name MQ40 \
			-filter {params.MQRankSum:q} --filter-name MQRankSum-12.5  \
			-filter {params.RPRS:q} --filter-name ReadPosRankSum-8 
		      	-O {output[0]}")
		
rule gatk_unfiltered_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/gatk_unfiltered.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp_gatk.vcf")
	params:
		ploidy = len(get_pop_range(props, outdir, proportions))
	run:
		shell("gatk HaplotypeCaller -R {input[0]} -I {input[1]} -ploidy {params.ploidy} -O {output.temp_file}")	
		shell(" bcftools annotate --rename-chrs {input.rename_file} {output.temp_file} > {output[0]}")			

rule varscan_call_extra_filter:
	input: 
		unfiltered_vcf = "{outdir}/sample{ii}/vcf/temp5.vcf,
		reference = reference,
		bam = "{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file,
		filter_script = varscan_filter
	output:
		"{outdir}/sample{ii}/vcf/varscan_extra_filter.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp4.vcf"),
		temp_unfiltered = temp("{outdir}/sample{ii}/vcf/temp4.vcf"),
		temp_file2 = temp("{outdir}/sample{ii}/vcf/temp4.vcf.gz"),
		readcounts = temp("{outdir}/sample{ii}/vcf/temp4.variant.readcounts"),
		bed = temp("{outdir}/sample{ii}/vcf/temp4.bed"),
		filter_pass = "{outdir}/sample{ii}/vcf/varscan_variants.filter.pass",
		filter_fails = "{outdir}/sample{ii}/vcf/varscan.vcf.fail"
	params:
		filter_prefix = "{outdir}/sample{ii}/vcf/varscan_variants.filter",
	run:		
		shell("convert2bed -i vcf -o bed < {input.unfiltered_vcf} > {output.bed}")
		shell("bam-readcount -q 1 -b 20 -f {output.reference} -l {output.bed} {input.bam} > {output.readcounts}")
		shell("perl {input.filter_script} {output.temp_unfiltered} {output.readcounts} â€“output-basename {params.filter_prefix}")
		shell("mv outfile.pass {output.temp_file}")
		shell("mv outfile.fail {output.filter_fails}")
		shell("bgzip -c {output.temp_file} ")
                shell("tabix -f -p vcf {output.temp_file2} ")
                shell("bcftools annotate --rename-chrs {input.rename_file} {output.temp_file2} > {output[0]}")		
		
rule varscan_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/varscan.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp5.vcf"),
		temp_file2 = temp("{outdir}/sample{ii}/vcf/temp5.vcf.gz"),
	run:
		shell("samtools mpileup -f {input[0]} {input[1]} \
			| varscan mpileup2snp - --output-vcf 1 --min-coverage 10 --min-var-freq 0.10 --p-value 0.10 > {output.temp_file}")
		shell(" bgzip -c {output.temp_file} > {output.temp_file2}")
		shell(" tabix -f -p vcf {output.temp_file2} ")
		shell(" bcftools annotate --rename-chrs {input.rename_file} {output.temp_file2} > {output[0]}")
		
rule freebayes_call:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/freebayes.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp6.vcf"),
		temp_file2 = temp("{outdir}/sample{ii}/vcf/temp6.vcf.gz")
	run:
		shell("freebayes -f {input[0]} -p 1 --pooled-continuous -0 {input[1]} > {output.temp_file}")
		shell(" bgzip -c {output.temp_file}")
		shell("tabix -f -p vcf {output.temp_file2} ")
		shell("bcftools annotate --rename-chrs {input.rename_file} {output.temp_file2} > {output[0]}")
		
rule freebayes_call_unfiltered:
	input: 
		reference,
		"{outdir}/sample{ii}/aln.srt.bam",
		rename_file = rename_file
	output:
		"{outdir}/sample{ii}/vcf/freebayes_unfiltered.vcf",
		temp_file = temp("{outdir}/sample{ii}/vcf/temp7.vcf"),
		temp_file2 = temp("{outdir}/sample{ii}/vcf/temp7.vcf.gz")
	run:
		shell("freebayes -f {input[0]} -p 1 --pooled-continuous {input[1]} > {output.temp_file}")
		shell(" bgzip -c {output.temp_file} ")
		shell(" tabix -f -p vcf {output.temp_file2} ")
		shell(" bcftools annotate --rename-chrs {input.rename_file} {output.temp_file2} > {output[0]}")

rule seq2msa:
	input:
		reference,
		"{outdir}/sample{ii}/seq_{jj}.fasta"
	output:
		temp("{outdir}/sample{ii}/msa/msa_seq_{jj}.fasta")
	shell:
		"cat {input} > {output}"

rule msa2vcf:
	input: 
		"{outdir}/sample{ii}/msa/msa_seq_{jj}.fasta"
	output:
		temp("{outdir}/sample{ii}/vcf/true_vcf_seq_{jj}.vcf")
	conda:
		"envs/snp-sites.yaml"
	shell:
		"snp-sites -v -o {output} {input}"	       

rule comparison_vcfs:
	input:
		"{outdir}/sample{ii}/vcf/{caller}.vcf",
		"{outdir}/sample{ii}/vcf/true_vcf_seq_{jj}.vcf"
	output:
		temp("{outdir}/sample{ii}/vcf/comparison/{caller}_seq_{jj}.diff.sites_in_files")
	params:
		out_prefix = "{outdir}/sample{ii}/vcf/comparison/{caller}_seq_{jj}"
	conda:
		"envs/vcftools.yaml"
	shell:
		"vcftools --vcf {input[0]} --diff {input[1]} --diff-site --out {params.out_prefix}"
		
rule validate:
	input:
		comparison_vcfs = expand("{{outdir}}/sample{{ii}}/vcf/comparison/{{caller}}_seq_{jj}.diff.sites_in_files", jj = pop_size_ar),
		reference = reference
	output:
		"{outdir}/sample{ii}/analysis/analysis_{caller}.csv"	
	params:
		sample_index = "{ii}",
		caller = "{caller}",
		out_dir = "{outdir}/sample{ii}/analysis"
	conda:
		"envs/validate_env.yaml"
	script:
		"scripts/validate.py"
		
rule data_collection:
	input:
		expand("{{outdir}}/sample{ii}/analysis/analysis_{{caller}}.csv", ii = repeat_ar)
	output:
		"{outdir}/results_{caller}.csv"
	conda:
		"envs/validate_env.py"
	params:
		caller = "{caller}",
		out_dir = "{outdir}"
	script:
		"scripts/data_collection.py"

